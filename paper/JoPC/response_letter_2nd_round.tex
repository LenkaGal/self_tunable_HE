\documentclass[a4paper,10pt]{article}

\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{a4wide}
\usepackage{multicol}
\usepackage[ansinew]{inputenc}
\usepackage{color}
\usepackage{url}
%\usepackage{floatflt}
\usepackage{multirow}
\usepackage{rotating, graphicx}


\newcommand{\opt}{^{\star}} % \opt
\newcommand{\tr}{\intercal} % transpose



% RESPONSE LETTER SYNTAX:
% =====================================================
\newcommand{\change}[1]{\textcolor{red}{#1}}
\newcommand{\textblue}[1]{\textcolor{blue}{#1}}




\newcommand{\comment}[1]{
	\begin{itemize}
		\item \textbf{Comment:}\\ \sf{#1}
	\end{itemize}
}

\newcommand{\answer}[1]{
	\begin{itemize}
		\item[] \textbf{Answer:}\\ #1
	\end{itemize}
}

\newcommand{\pointout}[1]{\textcolor{blue}{#1}}
\definecolor{YJ}{rgb}{0.0,0.5,0.0}

% =====================================================


\newcommand{\diam}[1]{\mathrm{diam}\left(#1\right)}

% \newcommand {\mm}[1]{\textcolor{blue}{#1}}

%opening
\title{Response to the review comments}
\author{}
\date{}

\sloppy
\begin{document}
	
	\maketitle
	
	We thank the Reviewers for revisiting our manuscript and for all comments and suggestions.
	The document was modified according to these comments and we provide point-to-point answers below.
	All changes relative to our previous submission are highlighted in \change{red}. 
	
	\section*{Answer to Editor}
	The authors would like to thank the Editor for collecting the 2nd round of review comments. We revised the paper based on the Reviewer's comments, and incorporated the suggestions
	into our manuscript.

	
	\section*{Answer to Reviewer 1}
	\comment{ The authors have not addressed some of my comments in the previous submission thoroughly. I have the following follow-up comments:\\ 
	
	 The control performance with Qy = 500 is not quantified, and whether the performance benefits of the proposed method reported in Table 2 still remain is not clarified. Since Qy =500 would give a moderately tuned controller, it can provide a better overall performance than the two boundary controllers chosen with "extreme" tuning.
	}

	\answer{
		We apologize for providing answers that were considered not sufficient. We have carefully revisited our recent manuscript to appropriately address all the Reviewer's comments. 
				
		First, we revisited Table~\ref{tab:control_performance} to evaluate the required control performance criteria for the moderate MPC setup $Q_\mathrm{y} = 500$.
		The values highlighted in blue represent the scenarios when the controller with the investigated setup $Q_\mathrm{y} = 500$ performed as the best one, excluding the self-tunable MPC.
		
		We recall that Table~\ref{tab:control_performance} summarizes 3 control performance criteria evaluated for 4 operating conditions represented by reference step change. Hence, Table~\ref{tab:control_performance} investigates 12 control cases in total. 
		It can be seen, that the values related to the the setup $Q_\mathrm{y} = 500$ are the best in 5 out of 12 performance criteria, see Table~\ref{tab:control_performance}, blue. On the contrary, the self-tuned controller acquired 10 best values out of 12 performance criteria thanks to the tuning based on the varying operating conditions, see Table~\ref{tab:control_performance}, red. 
		
		When excluding the boundary controllers and comparing only the self-tunable controller with the setup $Q_\mathrm{y} = 500$, the moderate controller outperforms the self-tunable MPC in half of the performance criteria. It happens mostly in tracking the reference value upwards. Nevertheless, when the reference changes downwards, the self-tuned controller becomes significantly beneficial. Therefore, it supports implementing the tunable control technique. To support our statement, the average control performance for all controllers was also elaborated. As the average control performance was the main topic of the Reviewer's comment No.2, these data are analyzed in detail in the answer to the following comment.
		
		\begin{table}[h!]
			\begin{center}
				\caption{Control performance criteria.}
				\label{tab:control_performance}
				\begin{tabular}{c|c|c|c|c} 
					Reference change & $Q_\mathrm{y}$ & SSE [$^{\circ}\mathrm{C}^2$\,s] & $\sigma_{\mathrm{max}}$\,[\%] & $t_{\epsilon}$\,[s]  \\
					\hline
					\multirow{4}{*}{ 35\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1\,000 & 714 & 33.5 & 16.5 \\
					& 100 & 867 & 16.7 & 12.5 \\ 
					& 500 & \textblue{\textbf{583}} & 17.6 & \textblue{\textbf{7.5}} \\
					& self-tuned & \change{\textbf{678}} & \change{\textbf{15.2}} & \change{\textbf{9.5}}  \\ 
					\hline
					\multirow{4}{*}{ 45\,$^{\circ}$C $\rightarrow$ 50\,$^{\circ}$C } & 1\,000 & 365 & 47.2 & 5 \\
					& 100 & 606 & 23.3 & 26.5  \\ 
					& 500 & \textblue{\textbf{168}} & \textblue{\textbf{18.2}} & 6.5 \\
					& self-tuned & \change{\textbf{248}} & \change{\textbf{19.1}} & 9.5  \\ 
					\hline
					\multirow{4}{*}{ 50\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1\,000 & 245 & 18.9 & 6.5  \\
					& 100 & 398 & 79.6 & 31  \\ 
					& 500 & \textblue{\textbf{211}} & 22.3 & 8 \\
					& self-tuned & \change{\textbf{186}} & 24.6 & \change{\textbf{6.5}}  \\ 
					\hline
					\multirow{4}{*}{ 45\,$^{\circ}$C $\rightarrow$ 35\,$^{\circ}$C } & 1\,000 & 1\,024 & 18.4 & 22.5  \\
					& 100 & 1\,402 & 41.9 & 90  \\ 
					& 500 & 1064 & 25.6 & 67 \\
					& self-tuned & \change{\textbf{967}} & \change{\textbf{16.5}} & \change{\textbf{18.5}} 
				\end{tabular}
			\end{center}
		\end{table}
		
		To ensure a consistent flow and not to disturb the readability of the paper, we incline not to branch the case study also in the direction of the moderate setup, i.e., $Q_\mathrm{y} = 500$. We prefer to emphasize the consideration of the self-tuning method based on the carefully revised comment from the first round of review:
		
		\begin{quote}
			Obviously, if there exists a well-tuned ``universal'' controller that satisfies the requirements on the control performance in the whole range of the considered operating conditions, then the implementation of the self-tuning procedure is out of scope for such control application. Nevertheless, in numerous practical situations, using only one controller with a constant setup leads to poor or just ``satisfactory'' control results, i.e., the reference value is achieved, but with worse control performance, e.g., leading to high overshoots or settling times. When working on our laboratory case study, a set of different setups of penalty matrices was investigated. In each control scenario, the setup was beneficial only in some working conditions (tracking the reference upwards or downwards). Therefore, the closed-loop control performance is significantly improved by introducing the benefits of the self-tuning method based on the two well-tuned boundary MPC controllers.
		\end{quote}
	

	}

	\comment{
		For the metrics in Table 2, can the authors also report average values of the three metrics (relative improvements) obtained across the four set point changes considered? The average values would give an idea of the overall control performance. It seems that the overall performance for the settling time would be worse, and only little improvement in the overshoot metric?
	}

	\answer{
		We would like to thank the Reviewer for the comment on the relative improvements. If the values in the original Table~2 were averaged, it is true that it would lead to the misleading impression of the decreased performance in terms of the settling time and the average relative improvement of the overshoot would be very low. However, considering the average of these values would be unfair because of the way how the relative improvements were originally calculated. 		
		%To prevent such a missleading of our reader, we completely re-evaluated the relative improvements data in Table~2.
		
		First, we point out that the values in Table~2 were originally computed subject to the boundary controller with the best performance for each reference step change individually. Obviously, the negative numbers of the relative improvement represent deterioration compared to the best controller setup in the corresponding reference tracking. It means, that the base subject to which is every value calculated, changes. Therefore, averaging the values of the relative improvements would not be fair, as it would not reflect improvement subject to one controller with a constant setup.
		
		To avoid the unfair evaluation of the relative improvement, we extended Table~\ref{tab:improvement500} such that every performance criterion of the optimal MPC is compared subject to the self-tunable MPC, see Table~\ref{tab:improvement500}. In such way, the base subject to which the relative improvements are calculated, remains the same. Note, that following up on the Reviewer's comment No.1, we also added the evaluation of the controller with the moderate setup, i.e., $Q_\mathrm{y} = 500$ to support the statements from the answer to the previous comment.
		
		%Regarding the average values of the relative improvements, simple average of the values for every controller across all reference changes would not properly map the overall improvement. For example, let us compare the 79\% improvement in the settling time subject to the MPC setup $Q_\mathrm{y} = 100$ during the third and fourth reference tracking. In the third reference step change, the relative improvement of 79\% corresponds to the settling time difference $31 - 6.5 = 24.5$\,s. In the fourth reference step change, the relative improvement of 79\% corresponds to the settling time difference $90 - 18.5 = 71.5$\,s. Although the values in Table~\ref{tab:improvement500} provide an extended overview of how better or worse the self-tunable controller performed in the specific operating conditions, averaging the values across the reference changes would give a somewhat distorted idea. Therefore, some kind of ``normalization'' would lead to a better vision of the average control performance. Our idea is to first average the values of the control performance criteria for every controller setup across the reference changes, and then calculate the relative improvements from the averaged values, see Table~\ref{tab:average_improvement500}. The symbol $\bar{(.)}$ represents an average value of the corresponding criterion.
		
		Therefore, based on the explanation of our idea of the average control performance evaluation, at this place we would like to return to the Reviewer's comment No.1--to analyze whether the moderate controller performs better in the overall metric. Let us compare the average relative control improvement of the moderate MPC and the self-tunable approximated MPC. The Table~\ref{tab:improvement500} shows that although in average the SSE criterion corresponding to the self-tunable MPC  was 6\,\% worse, the rest of the criteria improved in average (the maximal overshoot improved by 14\,\% and the settling time improved by 58\,\%). Moreover, we recall that the moderate MPC controller is not advantageous for the decreasing reference step changes. Therefore, considering the proposed tunable technique is beneficial.
		
		\begin{table}[h!]
			\begin{center}
				\caption{Relative improvement of the control performance using the self-tunable explicit MPC controller.}
				\label{tab:improvement500}
				\begin{tabular}{c|c|c|c|c} 
					& Comparison with $Q_\mathrm{y}$ setup & $\delta$ SSE\,[\%] & $\delta \sigma_{\mathrm{max}}$\,[\%] & $\delta t_{\epsilon}$\,[\%]  \\
					\hline
					\multirow{3}{*}{ 35\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1000 & 5 &  121 & 74 \\
					& 100 & 28 &  10 & 32 \\ 
					& 500 & $-14$ & 16 & $-21$ \\
					\hline
					\multirow{3}{*}{45\,$^{\circ}$C $\rightarrow$ 50\,$^{\circ}$C } & 1000 & 47 & 147 &$-47$  \\ 
					& 100 & 144 &  22 & 179 \\ 
					& 500 & $-32$ & $-5$ & $-32$ \\
					\hline
					\multirow{3}{*}{50\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1000 & 32 &$-23$& 0 \\ 
					& 100 & 114 & 224 & 377 \\
					& 500 & 13 & $-9$ & 23 \\
					\hline
					\multirow{3}{*}{45\,$^{\circ}$C $\rightarrow$ 35\,$^{\circ}$C } &  1000 & 6 & 12 & 22 \\
					& 100 & 45 &  154 & 386 \\
					& 500 & 10 & 55 & 262 \\
					\hline					
					\multirow{3}{*}{Average} &  1000 & 23 & 64 & 12 \\
					& 100 & 83 &  102 & 244 \\
					& 500 & $-6$ & 14 & 58 
				\end{tabular}
			\end{center}
		\end{table}
		
%		\begin{table}[h!]
%			\begin{center}
%				\caption{Average control performance criteria.}
%				\label{tab:average_improvement500}
%				\begin{tabular}{c|c|c|c|c|c|c} 
%					$Q_\mathrm{y}$ & $\overline{\mathrm{SSE}}$ [$^{\circ}\mathrm{C}^2$\,s] & $\delta \overline{\mathrm{SSE}}$\,[\%] & $\bar{\sigma}_{\mathrm{max}}$\,[\%] & $\delta \bar{\sigma}_{\mathrm{max}}$\,[\%] & $\bar{t}_{\epsilon}$\,[s] & $\delta \bar{t}_{\epsilon}$\,[\%] \\
%					\hline
%					1000 & 587 & 13 &  29.5 & 57 & 15 & 15 \\
%					100 & 818 & 57 & 40.4 & 114 & 40 & 264 \\ 
%					500 & 506.5 & $-3$ & 20.9 & 11 & 22.5 & 102 \\
%					self-tuned & 519.8 & - & 18.9 & - & 11 & - 			
%				\end{tabular}
%			\end{center}
%		\end{table}
		
		As the fine-tuning of the trade-off MPC controlled is out of the primal scope of our paper, we prefer preserving the consistent flow of the manuscript. Therefore, we incline not to branch the story line in the direction of the moderate setup, i.e., $Q_\mathrm{y} = 500$. Hence, our preference is to keep the original comparison subject to the boundary controllers as follows:
		
		\begin{quote}	
		
		As can be seen in Table~\ref{tab:control_performance}, the real-time self-tuning of the explicit MPC controller helped to improve two to three criteria when tracking each reference value. 	
		\change{The relative improvement in the percentage, denoted by $\delta$, of using the self-tunable controller is summarized in Table~\ref{tab:improvement} for each reference step change separately. The values were computed as the difference between two criteria values corresponding to the optimal and self-tunable MPC, referred to the self-tunable MPC. The negative numbers represent deterioration of the specific performance criterion in the corresponding reference tracking.} 
		
		\begin{table}[h!]
			\begin{center}
				\caption{Relative improvement of the control performance using the self-tunable explicit MPC controller.}
				\label{tab:improvement}
				\begin{tabular}{c|c|c|c|c} 
					& Comparison with $Q_\mathrm{y}$ setup & $\delta$ SSE\,[\%] & $\delta \sigma_{\mathrm{max}}$\,[\%] & $\delta t_{\epsilon}$\,[\%]  \\
					\hline
					\multirow{3}{*}{ 35\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1000 & 5 &  121 & 74 \\
					& 100 & 28 &  10 & 32 \\ 
					\hline
					\multirow{3}{*}{45\,$^{\circ}$C $\rightarrow$ 50\,$^{\circ}$C } & 1000 & 47 & 147 &$-47$  \\ 
					& 100 & 144 &  22 & 179 \\
					\hline
					\multirow{3}{*}{50\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1000 & 32 &$-23$& 0 \\ 
					& 100 & 114 & 224 & 377 \\
					\hline
					\multirow{3}{*}{45\,$^{\circ}$C $\rightarrow$ 35\,$^{\circ}$C } &  1000 & 6 & 12 & 22 \\
					& 100 & 45 &  154 & 386 \\
					\hline
					\multirow{3}{*}{Average} &  1000 & 23 & 64 & 12 \\
					& 100 & 83 &  102 & 244
				\end{tabular}
			\end{center}
		\end{table}	
	
	Compared to the considered non-self-tunable controllers, the control trajectories and the evaluated quality criteria confirmed the improved control performance for the reference tracking control problem of the heat exchanger with the non-linear and asymmetric behavior. Implementing a self-tunable explicit MPC controller leads to improved control performance in the most analyzed quality criteria, see Table~\ref{tab:improvement}.	
	\change{In average, the control performance criteria improved compared to the upper and lower boundary MPC respectively as follows: the squared-error-based criterion (SSE) reduced by 23\% and 83\%, the maximal overshoot/undershoot $\sigma_{\mathrm{max}}$ reduced by 64\% and 102\%, and the settling time $t_{\epsilon}$ reduced by 12\% and 244\%.}
	

% Relative improvement - subject to the specific investigated controller (old method)			
%			\begin{table}[h!]
%				\begin{center}
%					\caption{Relative improvement of the control performance using the self-tunable explicit MPC controller.}
%					\label{tab:improvement}
%					\begin{tabular}{c|c|c|c|c} 
%						Reference change & Comparison with $Q_\mathrm{y}$ setup & $\delta$ SSE\,[\%] & $\delta \sigma_{\mathrm{max}}$\,[\%] & $\delta t_{\epsilon}$\,[\%]  \\
%						\hline
%						\multirow{2}{*}{ 35\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1000 & 5 &  55 & 42 \\
%						& 100 & 22 &  9 & 24 \\  
%						\hline
%						\multirow{2}{*}{45\,$^{\circ}$C $\rightarrow$ 50\,$^{\circ}$C } & 1000 & 32 & 59 &$-90$  \\ 
%						& 100 & 59 &  18 & 64 \\ 
%						\hline
%						\multirow{2}{*}{50\,$^{\circ}$C $\rightarrow$ 45\,$^{\circ}$C } & 1000 & 24 &$-30$& 0 \\ 
%						& 100 & 53 & 69 & 79 \\
%						\hline
%						\multirow{2}{*}{45\,$^{\circ}$C $\rightarrow$ 35\,$^{\circ}$C } &  1000 & 6 & 11 & 18 \\
%						& 100 & 31 &  61 & 79 
%					\end{tabular}
%				\end{center}
%			\end{table}	
	
% Average - subject to the specific investigated controller	(old method)
%		\begin{table}[h!]
%		\begin{center}
%			\caption{Average control performance criteria.}
%			\label{tab:average_improvement}
%			\begin{tabular}{c|c|c|c|c|c|c} 
%				$Q_\mathrm{y}$ & $\overline{\mathrm{SSE}}$ [$^{\circ}\mathrm{C}^2$\,s] & $\delta \overline{\mathrm{SSE}}$\,[\%] & $\bar{\sigma}_{\mathrm{max}}$\,[\%] & $\delta \bar{\sigma}_{\mathrm{max}}$\,[\%] & $\bar{t}_{\epsilon}$\,[s] & $\delta \bar{t}_{\epsilon}$\,[\%] \\
%				\hline
%				1000 & 587 & 13 &  29.5 & 57 & 15 & 15 \\
%				100 & 818 & 57 & 40.4 & 114 & 40 & 264 \\ 
%				self-tuned & 519.8 & - & 18.9 & - & 11 & - 		
%			\end{tabular}
%		\end{center}
%	\end{table}

		\end{quote}

	
	
	}
	
	\comment{
		All the three performance metric are related to the controlled temperature variable. Why did the authors not consider any metric related to the control input?	
	}

	\answer{
		We thank the Reviewer for commenting on the control performance criteria evaluated subject to the control input. This kind of criteria usually reflects some costs or energy demands associated with the control. Although we considered such a numerical evaluation, finally we decided not to include the criteria for the following reasons. 
		
		The first admissible kind of criterion related to the control input could be intuitively some, potentially weighted, integral-of-squared input (ISI) or, in a discrete-time manner, sum-of-squared input (SSI). These criteria correspond to the summing of the control input, i.e., voltage to set the operating speed of the pump. However, the operating speed of the pump itself does not play any significant role in the costs of the control and, hence, is negligible. 
		Therefore, the control inputs could be converted to the amount of the heating medium transported to the heat exchanger during the whole control experiment. Nevertheless, the heating medium is dosed to the heat exchanger plant in a recycle setup, i.e., the same amount of heating medium is re-used during operation, see the corresponding setup scheme in Figure 3 of the manuscript. As such an evaluation would represent fictitious performance criteria not related to the actual plant setup, we prefer not to confuse the reader by such a criterion. 
		
		Another criterion related to the control input we considered was the energy consumed to pre-heat the heating medium in the heater. Although the energy consumption may sound as a relevant criterion, this is not directly associated with the MPC's control inputs. The reason is that the consumed energy corresponds to the control involving the auxiliary proportional controller, which sets the electric power. Therefore, any energy minimization should be primarily addressed by fine tuning of this auxiliary controller. To conclude, we prefer not to include this criterion that is unrelated to the MPC controller and keep the evaluation of the control inputs in the visual form of the profiles in Figure~10 in the manuscript.		
	}
	
	
	\comment{
		In addition, the authors only summarize the best case performance improvements in the conclusions. This can be a bit misleading to readers since the proposed method also performs worse (significantly) in some parts of the simulations. So summarizing average values would be more appropriate to give a better picture of the overall performance.
	}

	\answer{
		We thank the Reviewer for pointing out the confusing communication of the control performance improvements. Based on the results related to relative improvements reported in our answer to the Reviewer's comment No.2, we updated the section Conclusion which now reads as follows: 
		
		\begin{quote}
			To properly investigate the control results, the control performance was also judged quantitatively using a set of quality criteria. The self-tunable control approach outperformed the conventional control strategy handling just a single controller, i.e., non-tunable controller. \change{In average, the control performance criteria improved compared to the upper and lower boundary MPC respectively as follows: the squared-error-based criterion (SSE) reduced by 23\,\% and 83\,\%, the maximal overshoot/undershoot $\sigma_{\mathrm{max}}$ reduced by 64\,\% and 102\,\%, and the settling time $t_{\epsilon}$ reduced by 12\,\% and 244\,\%.}
		\end{quote}
	}
	
	
	\comment{
		Based on the responses to my previous comments, it appears that the applicability of the proposed self-tunable explicit MPC method is limited to "small-scale multivariable systems, with decoupled dynamics"? If so, please mention this clearly in the abstract.
	}

	\answer{
		We incorporated the Reviewer's suggestion into the Abstract as follows:
		
		\begin{quote}
			The tunable approximated explicit model predictive control (MPC) comes
			with the benefits of real-time tunability without the necessity of solving the optimization problem online. This paper provides a novel self-tunable control policy that does not require any intervention from the control engineer during operation in order to retune the controller subject to the changed working conditions. Based on the current operating conditions, the autonomous tuning parameter scales the control input using linear interpolation between the boundary optimal control actions. The adjustment of the tuning parameter depends on the current reference value, which makes this strategy suitable for reference tracking problems. Furthermore, a novel technique for scaling the tuning parameter is proposed. This extension exploits different ranges of the tuning parameter assigned to specified operating conditions. \change{The self-tunable technique is suitable for SISO (single-input and single-output) systems and MIMO (multiple-input and multiple-output) systems with decoupled dynamics.} The self-tunable explicit MPC was implemented on a laboratory heat exchanger with nonlinear and asymmetric behavior. The asymmetric behavior of the plant was compensated by tuning the controller’s aggressiveness, as the negative or positive sign of reference change was considered in the tuning procedure. The designed self-tunable controller improved control performance by decreasing sum-of-squared control error, maximal overshoots/undershoots, and settling time compared to the conventional control strategy based on a single (non-tunable) controller.
		\end{quote}

	}

	\section*{Answer to Reviewer 2}
	\comment{My comments from the previous round have been fully address. I suggest publication.}
	
	\answer{		
		We thank the Reviewer for reviewing our revised manuscript.		
	}




	

	
	
	%\bibliographystyle{plain}
	%\bibliography{references}
	
\end{document}


