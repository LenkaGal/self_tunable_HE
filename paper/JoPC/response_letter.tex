\documentclass[a4paper,10pt]{article}

\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{a4wide}
\usepackage{multicol}
\usepackage[ansinew]{inputenc}
\usepackage{color}
\usepackage{url}
%\usepackage{floatflt}
\usepackage{multirow}
\usepackage{rotating, graphicx}


\newcommand{\opt}{^{\star}} % \opt
\newcommand{\tr}{\intercal} % transpose



% RESPONSE LETTER SYNTAX:
% =====================================================
\newcommand{\change}[1]{\textcolor{red}{#1}}

\newcommand{\comment}[1]{
	\begin{itemize}
		\item \textbf{Comment:}\\ \sf{#1}
	\end{itemize}
}

\newcommand{\answer}[1]{
	\begin{itemize}
		\item[] \textbf{Answer:}\\ #1
	\end{itemize}
}

\newcommand{\pointout}[1]{\textcolor{blue}{#1}}
\definecolor{YJ}{rgb}{0.0,0.5,0.0}

% =====================================================


\newcommand{\diam}[1]{\mathrm{diam}\left(#1\right)}

% \newcommand {\mm}[1]{\textcolor{blue}{#1}}

%opening
\title{Response to the review comments}
\author{}
\date{}

\sloppy
\begin{document}
	
	\maketitle
	
	We would like to thank the reviewers for the constructive and thoughtful comments on our manuscript.
	We revised the document based on these comments and we provide point-to-point answers below.
	All changes relative to our initial submission are highlighted in \change{red}.
	
	\section*{Answer to Editor}
	We would like to thank the Editor for summarizing substantial and high-quality review comments, which helped us to improve our manuscript's quality. We revised the paper based on the reviewers' comments and incorporated the suggestions into our manuscript. We reformulated or added the corresponding statements to clarify the ideas. 

	
	\section*{Answer to Reviewer 1}
	\comment{The paper develops a method to automatically tune explicit MPC controllers, and demonstrates application of the proposed approach on a laboratory scale heat exchanger system. Overall, the paper is well written and the presented ideas and experimental results are clear. However, the following points should be addressed before publication: \\
	
	The main motivation that a practitioner may want different controller tunings based on operating scenarios and different sizes of reference changes/disturbances does not clearly stand out in the introduction section. The initial few paragraphs can be revised to clearly emphasize the need of a "self-tunable" MPC controller in practice.
	}

	\answer{
		
		We thank the Reviewer for pointing out unclear motivation for self-tunable control approach in section Introduciton. 
		In order to clearly emphasize the need of a self-tunable technique, we revised the Introduction section in a following way:
		\begin{quote}
			TODO: Update the introduction
			%The paper~\cite{self_tunable} pushes the idea of tunable explicit MPC further and deals with the issues of practical industrial-oriented implementation.
		\end{quote}
	}


	\comment{
		The authors state, "The lower computational complexity makes the explicit MPC more suitable for a practical industrial implementation." in the introduction section. It should be noted, however, that the explicit MPC suffers from the curse of dimensionality, and the number of polytopic regions in the PWA control law can grow exponentially with the size of states, control inputs, and the MPC forecasting horizon. Thereby, making it not practically implementable for a large class of industrial systems.
	}

	\answer{		
		
		We thank the reviewer for an important comment on application range of the proposed control method. We reformulated the corresponding sentence to make the implementation limits clear:
		\begin{quote}
			\change{If the MPC design problem can be pre-solved explicitly offline, the consequent reduced online computational complexity makes the explicit MPC more suitable for a practical industrial implementation.}
		\end{quote}
	}
	
	\comment{
		The main idea behind the self-tunable approximate explicit MPC controller is that two extreme controllers are designed with aggressive and slow tunings called the "boundary controllers", and a linear interpolation of those two controllers is taken to produce the final control input. How can this approach be applied to multivariable interacting systems with multiple control inputs?
	}

	\answer{
		The approach of self-tunable technique can be extended also to multivariable systems by utilizing only single value of the tuning parameter $\rho$ for the interpolation of the value of every control input. It is suggested in Eq.~(8) that the tuning parameter $\rho$ can be calculated as the maximal value of all the tuning parameters computed for every output reference. However, this is straightforward to implement only for decoupled systems. If there are strong interactions between the system states, the self-tunable technique is difficult to design. (My mame decoupled system?). To give the reader a clear view on the apllicability of the proposed approach, we added the following explanation to the manuscript:
		TODO
	}

	
	\comment{
		In the final simulation studies presented, the closed-loop performance of the self-tuned approximate MPC is compared only with the two extreme boundary controllers. However, a moderately tuned (E.g, Qy=500-600) "optimal" MPC controller may also provide a reasonable and potentially better performance than the two boundary controllers. I encourage the authors to comment on its performance and elaborate whether the control improvements reported in Table 2 still remain.
	}

	\answer{		
		We thank the reviewer for the comment on the performance of the proposed method. Obviously, if there exists a well-tuned (``universal'') controller that satisfies the requirements on the control performance in the whole range of the considered operating conditions, then the implementation of the self-tuning procedure is out of scope for such control application. Nevertheless, there are numerous practical situations, when using only one controller with a constant setup leads to poor or just ``satisfactory'' control results, i.e., the reference value is achieved, but with worse control performance, e.g., leading to high overshoots or settling times. When working on our laboratory case study, a set of different setups of penalty matrices was investigated, among them also the requested value of $Q_\mathrm{y} = 500$. In this control scenario, the control performance was comparable with the self-tuned controller for the first two step changes of the reference value (tracking the reference upwards). However, when the reference was tracked downwards, significant undershoots were present -- similar to the closed-loop performance of the lower boundary controller, i.e., $Q_\mathrm{y} = 100$. Therefore, these observations support the fact that the general aim of the control, i.e., achieving the reference value, is satisfied, but the closed-loop control performance is improved by introducing the benefits of the self-tuning based on the two boundary MPC controllers.
		\begin{quote}
			TODO
		\end{quote}		
	}


	\comment{
		The performance of the two boundary controllers shown in Figures 6 and 7 are also depicted in Figures 10 and 11. So some of the figures can be removed for a concise presentation of the results.
	}

	\answer{
		We removed the Figure 6 and 7 in order to improve the concise presentation of the control results.
	}
	
	\comment{
		Unmeasured disturbances are encountered in a large-class of industrial applications, and treating such disturbances is almost a required feature in the control algorithm to be considered for practical deployment. I recommend the authors to comment on how can the approach be applied to systems with unmeasured disturbances, or what complications may arise.
	}
	
	\answer{		
		We thank the Reviewer for this important comment on the reliable implementation in the industrial applications. We revisited the corresponding text in section Conclusion containing the comments on disturbances and incorporated also the answer on unmeasured disturbances. As the revised extended text includes ideas and comments reminding discussion more than conclusion, this part was transferred to the section Results and discussion, and now reads as follows:
		\begin{quote}
			Note, this strategy relies on a proper design of the two boundary controllers.
			In case a non-negligible disturbance occurs, both boundary controllers
			should be able to solve a disturbance rejection problem, as the final
			value of the manipulated variables is interpolated between them. \change{To address the impact of the disturbances directly in the construction of the MPC controller design, a robust MPC strategy should be considered, see e.g.~\cite{PR11}. Obviously, any robust MPC design method leads to conservative control actions as some portion of performance is scarified to compensate the impact of the disturbances. Nevertheless, if it is possible to obtain the explicit (multi-parametric) solution of the robust explicit MPC offline, then exactly the same self-tuning procedure is applicable to interpolate between the control actions from the robust controllers.} 
		\end{quote}	
	}


	
	\section*{Answer to Reviewer 2}	

	\comment{
		A self-tuning explicit MPC scheme is presented and applied to a heat exchange process. The main contribution above the authors other work appears to be the self-tuning aspect. Overall, the paper would greatly benefit from a thorough revision, clarifying ambiguous definitions, discussions, and descriptions. Also, the experimental setup should be clarified, as important dynamics that seem relevant (hot stream dynamics) appear to be ignored, raising doubts about the repeatability and therefore, conclusions drawn from the experiments. My specific comments are listed below.
		
		In the abstract, define what the term "properly tune the controller" means.
	}

	\answer{		
		We agree that the used formulation sounds vague, therefore, we reformulated the corresponding sentence in Abstract as follows:
		\begin{quote}
			This paper provides a novel self-tunable control policy that does not require any interventions of the control engineer during operation in order to \change{retune the controller}.
		\end{quote}			
	}

	\comment{
		Optimize the phrasing of the second paragraph of the introduction. The phrasing makes it sounds like heat exchangers are energy demanding, but I assume the intended meaning is that the utility generation for heating/cooling is energy-demanding.
	}

	\answer{
		We thank the Reviewer for this important comment. We utilized the Reviewer's suggested formulation in a following way:
		\begin{quote}
			\change{Simultaneously, the utility generation for heating or cooling is energy-demanding.}
		\end{quote}	
	}

	\comment{
		Define what is meant by asymmetric behavior.
	}

	\answer{
		We revisited the Introduction section in order to clearly define the asymmetric behavior at the place of its first occurrence.
		\begin{quote}
			\change{From the control viewpoint, the controller design for the heat exchangers is a challenging task due to the necessity to take into account the nonlinear and asymmetric behavior of the device, i.e. different plant behavior when the temperature is increasing, in contrast to the behavior when the temperature is decreasing, see~\cite{RL20}.}
		\end{quote}	
		
	}


	\comment{
		What are the assumptions on the penalty matrices? Include an explicit statement of these assumptions Section 2.1 (e.g., must be diagonal matrices).
	}

	\answer{
		We revisited the Section 2.1 in order to define the assumptions on the penalty matrices of the optimization problem. The corresponding part reads as:
		\begin{quote}
			The sets $\mathcal{U} \subseteq \mathbb{R}^{n_{\mathrm{u}}}$, $\mathcal{Y} \subseteq \mathbb{R}^{n_{\mathrm{y}}}$ are convex polytopic sets of physical constraints on inputs and outputs, respectively. These sets include the origin in their strict interiors. \textcolor{blue}{The penalty matrices are expected to ensure strictly convex optimization problem of MPC design. Therefore,} the penalty matrix $Q_\mathrm{y} \change{\succeq 0} \in \mathbb{R}^{n_{\mathrm{y}} \times n_{\mathrm{y}}}$ penalizes the squared control error, i.e., the deviation between the output and output reference value $y_\mathrm{ref}$. The matrix $R \change{\succ 0} \in \mathbb{R}^{n_{\mathrm{u}} \times n_{\mathrm{u}}}$ penalizes the squared value of control inputs. 
			%
			The value of integrator is also penalized in the cost function with the penalty matrix $Q_\mathrm{I} \change{\succeq 0} \in \mathbb{R}^{n_{\mathrm{y}} \times n_{\mathrm{y}}}$. \change{All the penalty matrices are considered to be diagonal due to the applicability of the self-tunable explicit MPC approach.}
			The parameter $\theta \in \Theta$ in Eq.~(1f) represents the initial condition of the optimization problem for which it is parametrically pre-computed. 
		\end{quote}	
	}

	\comment{
		Similarly, for the two boundary controllers explain the assumptions on the penalty matrices. Clearly, if the "upper" boundary matrices are equivalent to the "lower" boundary matrices multiplied by a scalar, there will be no difference between the solutions obtained by solving either controller. Perhaps, this is what meant by statement: "The boundary explicit controllers have the same structure and setup, except for one of the penalty matrices - the tuned one", but this statement can be further clarified (which matrix is the tuned one referring to?).
	}

	\answer{
		To explain the assumptions on the penalty matrices and specify the tuned matrix, we revisited the text in the corresponding paragraph of the Section 2.2 in the following way:
		\begin{quote}
			The idea of approximated tunable explicit MPC comes from the work ~\cite{Klauco_tunable}, where the control action is calculated based on linear interpolation between two boundary control actions. These control actions result from evaluating two boundary explicit MPCs. The boundary explicit controllers have the same structure and setup, except for one of the penalty matrices -- the tuned one. \change{Based on the specific control application, any penalty matrix can be chosen as the tuned parameter, i.e., this approach is applicable for any tuning parameter. The boundary penalty matrices follow the assumptions on the penalty matrices from Section 2.1 and are diagonal matrices such that $\lambda_{i,\mathrm{L}} \le \lambda_{i,\mathrm{U}}$, $\forall i = 1,\dots,s$, where $\lambda$ denotes the vector of eigenvalues of the penalty matrix, $s$ is the rank of the tuned penalty matrix, and $L$, $U$ denote the lower and upper boundary setup respectively. }
		\end{quote}	
		
		\begin{quote}
			The idea of approximated tunable explicit MPC comes from the work ~\cite{Klauco_tunable}, where the control action is calculated based on linear interpolation between two boundary control actions. These control actions result from evaluating two boundary explicit MPCs. The boundary explicit controllers \change{are constructed by solving the optimization problem having} the same structure and setup, except for one of the penalty matrices -- the tuned one. \textcolor{blue}{The tuned matrix is either the state penalty or the control input penalty matrix.} \change{Based on the specific control application, and following the well-known LQR-based tuning rules, any penalty matrix can be selected as the tuned parameter. Therefore, this approach is applicable for any tuning parameter. The boundary penalty matrices follow the assumptions on the penalty matrices from Section 2.1 and are diagonal matrices such that $\lambda_{i,\mathrm{L}} \le \lambda_{i,\mathrm{U}}$, $\forall i = 1,\dots,s$, where $\lambda$ denotes the vector of eigenvalues of the penalty matrix, $s$ is the rank of the tuned penalty matrix, and $L$, $U$ denote the lower and upper boundary setup respectively. }
		\end{quote}	
	}

	\comment{
		Please clarify the last sentence on page 7, extending into page 8, which describes the tuning process as systematic, but the description appears to be ad hoc and depend on the system.
	}

	\comment{
		Does the method only support SISO or MIMO system with decoupled pairs of inputs/outputs? This seems to be suggested by the statement made on page 9. If so, this should be stated explicitly in the problem setup.
	}

	\comment{
		How is the aggressiveness of the controller being defined?
	}

	\answer{
		The aggressiveness of the MPC controller is associated with the setup of penalty matrices, namely $Q_\mathrm{y}$, $Q_\mathrm{I}$, $R$, as it determines the aggressiveness of the final control input. In general, followign the LQR design rules, higher penalization of the controlled states or control error (higher values of the diagonal elements of matrices $Q_\mathrm{y}$ and $Q_\mathrm{I}$) leads to more aggressive control actions. This process is similar to increasing the proportional gain in PID controller. On the contrary, higher penalization of the input variable through the penalty matrix $R$ leads to more sluggish control, see e.g.~\cite{Maciejowski_MPC}. In order to make the notation of aggressive controller more clear for a reader, we added this description to the Section.
		
		\begin{quote}
			The paper~\cite{self_tunable} pushes the idea of tunable explicit MPC further and deals with the issues of practical industrial-oriented implementation. The procedure of the self-tunable controller technique is presented. The controller's aggressivity is tuned based on the difference between the reference value and the steady state corresponding to the model linearization point. \change{In the context of MPC, the aggressiveness is associated with the setup of the penalty matrices, as it determines the aggressiveness of the final control input. In general, higher penalization of the controlled states or control error in the cost function leads to more aggressive control actions. This process is similar to increasing the proportional gain in PID controller. On the contrary, higher penalization of the input variable leads to more sluggish control, see e.g.~\cite{Maciejowski_MPC}. The MPC tuning} based on the distance from the steady-state operating point represented a way how to compensate for the system's nonlinear behavior.
		\end{quote} 
	}
	
	\comment{
		What are the properties of the reference values selected? Are they reachable?
	}

	\answer{
		We would like to divide the answer in two parts as the reference value is present in MPC optimization problem in Eq.~(1) and also in the calculation process of the tuning parameter $\rho$ in Eq.~(7) and Eq.~(9). 
		
		First, regarding the MPC optimization problem, the reference signal is a parameter which is usually constrained such that it covers the operating range of the corresponding control application. Therefore, during the real-time control, the reference value can be selected only as a value from the feasible set determined offline, when constructing explicit MPC controller. If the MPC problem is precomputed also for non-reachable references, e.g., because it is not clear a priori which reference values will be set during control, this would ``only'' lead to larger explicit solution of MPC, as the consequence of larger range of reference signal. 

		Next, regarding the calculation of parameter $\rho$, the setup of reference value is strict and the reference value is reachable from the operating range to ensure that $0 \le \rho \le 1 $ holds. Otherwise, the interpolated control action would be the ``extrapolation'' leading to the loss of guarantees on the input/state constraints satisfaction, etc.		
		
			\begin{quote}
				TODO: Somehow update text in manusctipt?
			\end{quote}
	}

	\comment{
		In Eq. 7, there is a missing time dependence on rho and the "(k)" in $y_\mathrm{ref}$ should not be a subscript.
	}

	\answer{
		We thank the Reviewer for a careful review. The equation was corrected as follows:
		\begin{quote}
			\change{
			\begin{eqnarray*}				
				\rho (k) = \frac{\vert y_{\mathrm{ref}}(k) \vert}{d_{\max}}.
			\end{eqnarray*}
		}
		\end{quote} 
	
	}

	\comment{
		Please clarify the role of rho and dmax. What is the symbol $\lvert.\rvert$ mean for a vector (element-wise absolute value)? It seems that dmax would need to be inherently conservative, in the sense that it is the maximum magnitude of all possible references values. If this is the case, it would seem that rho would mostly be less than 1. On the other hand, if dmax is not the maximum magnitude of all possible reference, there is a possibility of rho $>$ 1. What happens in this case? Why is it appropriate to make rho closer to 1 for references with large magnitudes.
	}


	\comment{
		At the end of Section 2, it is mentioned that the positivity or negativity of the reference change could be considered. What does this mean? A precise mathematical description would be helpful.
	}

	\answer{
		To improve the readability of the manuscript, we added the mathematical description to the corresponding sentence. Moreover, based on the following comment, we added the description of asymmetric system behavior in this paragraph as follows:
		\begin{quote}
			Note, the relations in Eq.~(7) and Eq.~(8) operate with the absolute value of the reference. \change{It is not taken into account, whether the reference value changed upwards or downwards with respect to the system steady-state value placed in the origin, i.e., whether holds the inequality: $\Delta_\mathrm{ref}(k) = y_\mathrm{ref}(k)-y_\mathrm{ref}(k-1) > 0$ or $\Delta_\mathrm{ref}(k) < 0$. As many plants have nonlinear behavior with asymmetric nature (different behavior when the process variable is rising or decreasing), the positivity or negativity of the reference change could be considered in the controller self-tuning procedure to improve the control performance.}
		\end{quote}
	}

	\comment{
	 	Given the lack of clear definition of asymmetric behavior, the need for a modified self tuning technique (Section 3.2) is a bit unclear. A clear description of its need in the beginning of Section 3.2 would be helpful.
	}

	\answer{
		 We thank the Reviewer for this comment. Please, see the previous answer as the incorporation of this comment into the manuscript was merged with the previous comment, because it corresponds to the thoughts in the same paragraph.
	}


	\comment{
		In Definition 3.1, is the domain of gamma indeed R?
	}

	\answer{
		\textcolor{blue}{As this paper investigates laboratory implementation considering a SISO system, then} the parameter $\gamma$ depends on the value of $\rho$, which is also a scalar. From this it follows, that the domain of $\gamma$ is $\mathbb{R}$.
	}	

	\comment{
		Figure 4 seems out of place (should be after figure 1).
	}

	\answer{
		We thank the Reviewer for this attentive comment. We corrected the order of Figures.
	}

	\comment{
		A diagram or schematic of the heat exchange process would be helpful. Also, referring to the cold water stream as the feed when the outlet temperature is regulated is a bit confusing.
	}

	\comment{
		How was it determined that Qy has the most significant effect in the heat exchange process? What constitutes "significant effect"?
	}

	\answer{
		We thank the Reviewer for pointing out insufficient discussion on the selection of the tuning penalty matrix $Q_\mathrm{y}$. We revisited the corresponding paragraph to describe the tuning procedure.
		
		\begin{quote}
			The penalty matrices of the problem in Eq.~(1) were systematically tuned and the corresponding control setup was implemented on the laboratory heat exchanger for each of the considered explicit MPC setups. 
			First, the aim of tuning was to determine, which penalty matrix is the most suitable for real-time tuning. \change{Based on the set of experimentally collected data, the penalty matrix $Q_\mathrm{y}$ was chosen as the tuned one.} Based on the set of experimentally collected data, the most significant effect on the control trajectories had tuning the penalty matrix $Q_\mathrm{y}$, while still preserving a satisfactory control performance, i.e., without steady-state control error and significant oscillations around the reference value. Next, the boundary values of the tunable matrix $Q_\mathrm{y}$ were tuned as $Q_\mathrm{y, L}$ = 100 and $Q_\mathrm{y, U}$ = 1\,000.
		\end{quote}
		
		\begin{quote}
			\change{
			The penalty matrices of the problem in Eq.~(1) were systematically tuned and the corresponding control setup was implemented on the laboratory heat exchanger for each setup of the considered explicit MPC controllers. 
			First, the aim of the tuning procedure was to determine, which penalty matrix is the most suitable for real-time tuning. Based on the whole set of experimentally collected data, the penalty matrix $Q_\mathrm{y}$ was determined as the most relevant tuned penalty, as this penalty matrix had the most significant effect on the control trajectories. Tuning of $Q_\mathrm{y}$ preserved a satisfactory control performance without steady-state control error and without significant oscillations around the reference value. Next, the boundary values of the tunable matrix $Q_\mathrm{y}$ were tuned until the following limit values were determined based on the measured closed-loop control data: $Q_\mathrm{y, L}$ = 100 and $Q_\mathrm{y, U}$ = 1\,000.
			}
		\end{quote}
	}

	\comment{
		In the heat exchange process, the dynamics of the hot stream appears to be neglected. Why is this the case? I am not sure about the explanation given on why different steady-state inputs are observed. The flow rate of the hot stream is adjusted so the cold stream outlet temperature is maintained at the reference value is done. It seems, though not shown, that the hot stream inlet temperature is maintained to be constant. Based on the results, it would seem that the steady-state hot stream temperature is free to vary. What about the cold stream inlet temperature? Please given the trajectories of all these variables, or at least, the temperatures. What is the impact of the repeatability of the experiments given that the hot stream temperature is allowed to vary? In any case, the metrics presented in Table 1 are reported for one experiment per scenario. I would encourage computing these metrics for several experiments to ensure repeatability of the experiments and make the results more convincing.
	}
	\answer{
		We thank the Reviewer for the very insightful comment on the experiment setup. We find this comment comprises three closely related points to be answered individually.
		
		\textcolor{blue}{First, we confirm that the hot stream temperature is considered constant. This assumption is supported by the implementation of the auxiliary PID controller dedicated to controlling the temperature in the boiler/retention tank of the hot medium. Although the control profiles of the hot stream temperature ($T = 70^{\circ}$\,C) are not provided, the corresponding dynamics provided by the heat transfer were within the declared precision of the hot stream temperature sensor and hence negligible.}
		
		Next, we would like to make clear that the repeatability of the realized laboratory experiments was ensured by fixing all the relevant conditions, such as the cold medium dosed into the heat exchanger from the large retention tanks at the laboratory temperature and the constant inlet temperature of the heating medium.
		
		\textcolor{blue}{ Finally, we would like to address the doubts related to observing the varying steady-state values of the control inputs corresponding to the same value of the controlled variable - the outlet temperature of the heated medium. Although this performance may look like an error introduced during a single measurement, we realized a series of laboratory experiments to investigate this phenomenon with analogous results. The steady-state value of control input settled either in the close neighborhood of $U = 45\,\%$ (e.g., for $Q_{\mathrm{y}} = XXX, XXX$), or close to the value of $U = 55\,\%$ (e.g., for $Q_{\mathrm{y}} = XXX, XXX$). Therefore, after the detailed analysis, we state that this phenomenon originates from the physical construction of the heat exchanger due to the portion of heat released from the plates for the (relatively high) reference value around $T = 50^{\circ}$\,C.}
		
		\begin{quote}
			TODO: Zapracovat do clanku. 			
		\end{quote}
	}
	
	
	\bibliographystyle{plain}
	\bibliography{references}
	
\end{document}


